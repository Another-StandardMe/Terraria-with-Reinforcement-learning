import torch
import torch.multiprocessing as mp
import os
import time
from queue import Empty

from TerrariaPPO import PPO
from TerrariaENV import TerrariaEnv

class Args:
    """ å®šä¹‰è¶…å‚æ•° """
    model_path = "10000best.pt"
    seq_len = 4

    # CNN-Transformeræ¨¡å‹å‚æ•°
    img_feature_dim = 128
    transformer_dim = 128
    hidden_width = 64
    transformer_heads = 4
    transformer_layers = 1
    dropout_rate = 0.1

    # PPO è®­ç»ƒå‚æ•°
    gamma = 0.90
    lamda = 0.95  # è™½ç„¶ PPO æ›´æ–°ä¸­ä¸ä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥ä¾¿ä»¥åæ‰©å±•
    epsilon = 0.5
    K_epochs = 10
    entropy_coef = 0.01
    max_train_steps = 3e5
    batch_size = 4

    # ä¼˜åŒ–å™¨ & è®­ç»ƒ
    lr_a = 2e-4
    lr_c = 6e-4
    max_epochs = 10000
    save_step = 1000000
    clip_value = 0.4

    # Worker-Learner å¹¶è¡Œ
    num_workers = 1
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def get_args():
    return Args()

class Worker(mp.Process):
    """ é‡‡é›†æ•°æ®å¹¶å‘é€ç»™ Learner """
    def __init__(self, worker_id, data_queue, param_queue, epoch_sync_event, epoch_end_event, exit_event, args):
        super(Worker, self).__init__()
        self.worker_id = worker_id
        self.data_queue = data_queue
        self.param_queue = param_queue
        self.epoch_sync_event = epoch_sync_event  # ç”¨äºé€šçŸ¥ Learner æ–°æ•°æ®åˆ°ä½
        self.epoch_end_event = epoch_end_event      # ç”¨äºç­‰å¾… Learner å®Œæˆæœ¬è½®è®­ç»ƒ
        self.exit_event = exit_event
        self.args = args

    def run(self):
        print(f"ğŸš€ Worker {self.worker_id} åˆå§‹åŒ–ç¯å¢ƒ")
        env = TerrariaEnv(self.args.seq_len)
        # å®ä¾‹åŒ– PPOï¼ˆå†…éƒ¨è‡ªåŠ¨æ‰§è¡Œæ­£äº¤åˆå§‹åŒ–ï¼‰
        model = PPO(self.args)
        model.actor.to(self.args.device)

        for epoch in range(self.args.max_epochs):
            if self.exit_event.is_set():
                break

            print(f"ğŸ¯ Worker {self.worker_id} å¼€å§‹ Epoch {epoch + 1}/{self.args.max_epochs}")

            obs = env.reset()
            while obs is None:
                time.sleep(1)
                obs = env._get_observation()

            boss = env.check()
            if boss:  # å¦‚æœ boss == True
                print("â¸ï¸ ç¯å¢ƒå‡ºé”™ï¼Œé‡ç½®ç¯å¢ƒ...")
                obs = env.reset()

            # å¦‚æœ obs æ˜¯å•æ ·æœ¬ï¼ˆå½¢çŠ¶ [seq_len, 3, H, W]ï¼‰ï¼Œå¢åŠ  batch ç»´åº¦
            if obs.ndim == 4:
                obs = obs.unsqueeze(0)

            done = False

            while not done:
                if self.exit_event.is_set():
                    break

                # å°è¯•è·å–æœ€æ–°çš„æ¨¡å‹å‚æ•°
                try:
                    params = self.param_queue.get_nowait()
                    model.actor.load_state_dict(params)
                    model.actor.to(self.args.device)
                except Empty:
                    pass

                # è·å–åŠ¨ä½œå’Œ log_probï¼ˆget_action è¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œæ­¤å¤„è½¬æ¢ä¸ºå¼ é‡å¹¶è¡¥é½ batch ç»´åº¦ï¼‰
                action, log_prob = model.get_action(obs.to(self.args.device))
                action_tensor = torch.tensor(action, dtype=torch.long)
                if action_tensor.ndim == 1:
                    action_tensor = action_tensor.unsqueeze(0)
                log_prob_tensor = torch.tensor(log_prob, dtype=torch.float)
                if log_prob_tensor.ndim == 0 or log_prob_tensor.ndim == 1:
                    log_prob_tensor = log_prob_tensor.unsqueeze(0)

                next_obs, reward, done, _ = env.step(action)
                if next_obs is None:
                    continue
                if next_obs.ndim == 4:
                    next_obs = next_obs.unsqueeze(0)

                try:
                    # æ„é€ å•ä¸ªæ ·æœ¬æ•°æ®ï¼ˆæ¯ä¸ªå…ƒç´ éƒ½å¸¦æœ‰ batch ç»´åº¦ï¼‰
                    sample = (
                        obs.cpu().clone(),                      # [1, seq_len, 3, H, W]
                        action_tensor.cpu().clone(),            # [1, 2]
                        log_prob_tensor.cpu().clone(),          # [1] æˆ– [1,1]
                        torch.tensor(reward, dtype=torch.float).unsqueeze(0).cpu().clone(),  # [1]
                        next_obs.cpu().clone(),                 # [1, seq_len, 3, H, W]
                        torch.tensor(float(done), dtype=torch.float).unsqueeze(0).cpu().clone()  # [1]
                    )
                    self.data_queue.put_nowait(sample)
                    self.epoch_sync_event.set()  # é€šçŸ¥ Learner æ•°æ®å·²åˆ°ä½
                except Exception as e:
                    print(f"âš ï¸ Worker {self.worker_id}: æ•°æ®é˜Ÿåˆ—æ»¡ï¼Œè·³è¿‡å­˜å‚¨ï¼Œé”™è¯¯ä¿¡æ¯: {e}")

                obs = next_obs

            print(f"âœ… Worker {self.worker_id} ç»“æŸ Epoch {epoch + 1}")
            env.close()
            # å‘é€æœ¬è½®ç»“æŸä¿¡å·
            self.data_queue.put(("EPOCH_END", self.worker_id))
            print(f"âš ï¸ Worker {self.worker_id} ç­‰å¾… Learner å®Œæˆå½“å‰ Epoch çš„è®­ç»ƒ...")
            self.epoch_end_event.wait()  # ç­‰å¾… Learner é€šçŸ¥æœ¬è½® epoch æ•°æ®å¤„ç†å®Œæ¯•
            self.epoch_end_event.clear()
            print("----- æ¥ä¸‹æ¥é‡ç½®ç¯å¢ƒ -----")

        self.data_queue.put(("TERMINATE", self.worker_id))
        print(f"ğŸš€ Worker {self.worker_id} è®­ç»ƒå®Œæˆ")

class Learner(mp.Process):
    """ Learner ç«¯ï¼šæŒç»­è®­ç»ƒ """
    def __init__(self, model, data_queue, param_queue, epoch_sync_event, epoch_end_event, exit_event, args):
        super(Learner, self).__init__()
        self.model = model
        self.data_queue = data_queue
        self.param_queue = param_queue
        self.epoch_sync_event = epoch_sync_event  # ç”¨äºé€šçŸ¥æ–°æ•°æ®åˆ°è¾¾
        self.epoch_end_event = epoch_end_event      # ç”¨äºé€šçŸ¥ Worker å½“å‰ epoch å®Œæˆè®­ç»ƒ
        self.exit_event = exit_event
        self.args = args
        self.total_samples = 0
        self.active_workers = self.args.num_workers

    def run(self):
        self.model.actor.to(self.args.device)
        self.model.critic.to(self.args.device)
        print("ğŸ“¢ Learner å¼€å§‹è®­ç»ƒ")

        while self.active_workers > 0 or not self.data_queue.empty():
            try:
                data = self.data_queue.get(timeout=5)
                if isinstance(data, tuple):
                    # å¤„ç† Worker å‘æ¥çš„ä¿¡å·
                    if data[0] == "TERMINATE":
                        self.active_workers -= 1
                        print(f"âš ï¸ Learner æ”¶åˆ°ç»ˆæ­¢ä¿¡å·ï¼ŒWorker {data[1]} å·²é€€å‡º")
                        break
                        # continue # ç­‰å¾…å¤šä¸ªworkerç»“æŸæ—¶ä½¿ç”¨

                    elif data[0] == "EPOCH_END":
                        print(f"âš ï¸ Learner æ”¶åˆ° Epoch ç»“æŸä¿¡å·ï¼ŒWorker {data[1]} æœ¬è½®æ•°æ®è®­ç»ƒå®Œæˆ")
                        # é€šçŸ¥å¯¹åº” Worker å½“å‰ epoch è®­ç»ƒå®Œæˆ
                        self.epoch_end_event.set()
                        continue

                # ç›´æ¥ä¼ å…¥å•ä¸ªæ ·æœ¬æ•°æ®ï¼ˆä¿è¯æ•°æ®å„å…ƒç´ å¸¦æœ‰ batch ç»´åº¦ï¼‰
                self.model.update(data)
                self.total_samples += 1

                if self.total_samples % self.args.save_step == 0:
                    save_path = f"checkpoints/Terraria_checkpoint_{self.total_samples}.pth"
                    os.makedirs("checkpoints", exist_ok=True)
                    torch.save(self.model.actor.state_dict(), save_path)
                    print(f"ğŸ’¾ å®šæœŸä¿å­˜æ¨¡å‹: {save_path} (è®­ç»ƒæ•°æ®: {self.total_samples})")
                    self.param_queue.put({k: v.cpu() for k, v in self.model.actor.state_dict().items()})
            except Empty:
                print("âš ï¸ æ•°æ®é˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾…æ•°æ®...")
                time.sleep(1)

        save_path = "checkpoints/Terraria_final_model.pth"
        os.makedirs("checkpoints", exist_ok=True)
        torch.save({
            "actor": self.model.actor.state_dict(),
            "critic": self.model.critic.state_dict()
        }, save_path)
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {save_path}")
        print("âœ… Learner è®­ç»ƒå®Œæˆï¼Œé€šçŸ¥ Worker é€€å‡º")
        self.exit_event.set()

def train():
    mp.set_start_method("spawn", force=True)
    args = get_args()

    # æ–°å¢ epoch_end_eventï¼Œç”¨äºåŒæ­¥æ¯ä¸ª epoch çš„ç»“æŸ
    epoch_sync_event = mp.Event()
    epoch_end_event = mp.Event()
    exit_event = mp.Event()

    # å®ä¾‹åŒ– PPOï¼ˆå†…éƒ¨è‡ªåŠ¨æ‰§è¡Œæ­£äº¤åˆå§‹åŒ–ï¼‰
    agent = PPO(args)
    data_queue = mp.Queue(maxsize=6000)
    param_queue = mp.Queue()

    workers = [Worker(i, data_queue, param_queue, epoch_sync_event, epoch_end_event, exit_event, args)
               for i in range(args.num_workers)]
    learner = Learner(agent, data_queue, param_queue, epoch_sync_event, epoch_end_event, exit_event, args)

    for w in workers:
        w.start()
    learner.start()

    learner.join()
    exit_event.set()
    for w in workers:
        w.join()

    print("âœ… è®­ç»ƒå®Œæˆ")

if __name__ == "__main__":
    train()
