import torch
import torch.multiprocessing as mp
import numpy as np
import os

from queue import Empty
from Env_batch import TerrariaEnv
import time

#from env1 import TerrariaEnv
#from ppo3 import PPO
from batch_ppo import PPO


class Args:
    """ å®šä¹‰è¶…å‚æ•° """
    model_path = "E:\\terraria_project\\after_training_weight\\10000best.pt"
    seq_len = 8

    # **æ¨¡å‹å‚æ•°**
    img_feature_dim = 128
    transformer_dim = 64
    hidden_width = 128
    transformer_heads = 2
    transformer_layers = 3
    dropout_rate = 0.1

    # **PPO è®­ç»ƒå‚æ•°**
    gamma = 0.99
    lamda = 0.95
    epsilon = 0.2
    K_epochs = 10
    entropy_coef = 0.01

    # **ä¼˜åŒ–å™¨ & è®­ç»ƒ**
    lr_a = 3e-4
    lr_c = 1e-5
    max_epochs = 1
    save_step = 5600

    # **Worker-Learner å¹¶è¡Œ**
    num_workers = 1
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_args():
    return Args()


class Worker(mp.Process):
    """ é‡‡é›†æ•°æ®å¹¶å‘é€ç»™ Learner """

    def __init__(self, worker_id, data_queue, param_queue, epoch_sync_event, exit_event, args):
        super(Worker, self).__init__()
        self.worker_id = worker_id
        self.data_queue = data_queue
        self.param_queue = param_queue
        self.epoch_sync_event = epoch_sync_event
        self.exit_event = exit_event
        self.args = args

    def run(self):
        print(f"ğŸš€ Worker {self.worker_id} åˆå§‹åŒ–ç¯å¢ƒ")
        env = TerrariaEnv(self.args.model_path, self.args.seq_len)
        model = PPO(self.args)
        model.actor.to(self.args.device)

        for epoch in range(self.args.max_epochs):
            if self.exit_event.is_set():
                break

            print(f"ğŸ¯ Worker {self.worker_id} å¼€å§‹ Epoch {epoch + 1}/{self.args.max_epochs}")

            obs = env.reset()
            while obs is None:
                time.sleep(1)
                obs = env._get_observation()

            done = False

            while not done:
                if self.exit_event.is_set():
                    break

                # è·å–æœ€æ–°ç­–ç•¥
                try:
                    params = self.param_queue.get_nowait()  # è·å–æœ€æ–°çš„æ¨¡å‹å‚æ•°
                    model.actor.load_state_dict(params)  # åŠ è½½æœ€æ–°å‚æ•°
                except Empty:
                    pass

                action, log_prob = model.get_action(obs)

                next_obs, reward, done, _ = env.step(action)

                if next_obs is None:
                    continue

                # å­˜å‚¨æ•°æ®ï¼ˆå•æ ·æœ¬ï¼‰
                try:
                    self.data_queue.put_nowait((
                        obs.cpu(),
                        torch.tensor(action, dtype=torch.long),
                        torch.tensor(log_prob, dtype=torch.float),
                        torch.tensor(reward, dtype=torch.float),
                        next_obs.cpu(),
                        torch.tensor(float(done), dtype=torch.float)
                    ))
                    self.epoch_sync_event.set()  # é€šçŸ¥ Learner è®­ç»ƒ
                except:
                    print(f"âš ï¸ Worker {self.worker_id}: æ•°æ®é˜Ÿåˆ—æ»¡ï¼Œè·³è¿‡å­˜å‚¨")

                obs = next_obs

            print(f"âœ… Worker {self.worker_id} ç»“æŸ Epoch {epoch + 1}")
            time.sleep(1)

        self.data_queue.put(("TERMINATE", self.worker_id))  # âœ… ç»“æ„åŒ–ç»ˆæ­¢ä¿¡å·
        print(f"ğŸš€ Worker {self.worker_id} è®­ç»ƒå®Œæˆ")




class Learner(mp.Process):
    """ Learner ç«¯ï¼šæŒç»­è®­ç»ƒ """

    def __init__(self, model, data_queue, param_queue, epoch_sync_event, exit_event, args):
        super(Learner, self).__init__()
        self.model = model
        self.data_queue = data_queue
        self.param_queue = param_queue
        self.epoch_sync_event = epoch_sync_event
        self.exit_event = exit_event
        self.args = args
        self.total_samples = 0  # è®°å½•è®­ç»ƒçš„æ•°æ®é‡
        self.active_workers = self.args.num_workers  # è®°å½•å½“å‰æ´»è·ƒçš„ workers æ•°é‡

    def run(self):
        self.model.actor.to(self.args.device)
        self.model.critic.to(self.args.device)

        print("ğŸ“¢ Learner å¼€å§‹è®­ç»ƒ")

        batch_samples = []  # ç”¨äºæ”¶é›† batch
        while self.active_workers > 0:  # åªè¦æœ‰æ´»è·ƒçš„ workerï¼Œå°±ç»§ç»­
            try:
                data = self.data_queue.get(timeout=5)
                if isinstance(data, tuple) and data[0] == "TERMINATE":
                    self.active_workers -= 1
                    print(f"âš ï¸ Learner æ”¶åˆ°ç»ˆæ­¢ä¿¡å·ï¼ŒWorker {data[1]} å·²é€€å‡º")
                    continue  # ç»§ç»­å¤„ç†å…¶ä»–æ•°æ®

                batch_samples.append(data)
                self.total_samples += 1

                if len(batch_samples) >= 16:
                    self.model.update(batch_samples)
                    batch_samples = []

                    # æ¯è®­ç»ƒ 5600 ä¸ªæ•°æ®ä¿å­˜ä¸€æ¬¡æ¨¡å‹
                    if self.total_samples % self.args.save_step == 0:
                        save_path = f"checkpoints/Terraria_checkpoint_{self.total_samples}.pth"
                        os.makedirs("checkpoints", exist_ok=True)
                        torch.save(self.model.actor.state_dict(), save_path)
                        print(f"ğŸ’¾ å®šæœŸä¿å­˜æ¨¡å‹: {save_path} (è®­ç»ƒæ•°æ®: {self.total_samples})")

                        # åŒæ­¥æœ€æ–°æ¨¡å‹å‚æ•°åˆ° Worker
                        self.param_queue.put(self.model.actor.cpu().state_dict())  # å‘é€æœ€æ–°çš„æ¨¡å‹å‚æ•°

            except Empty:
                print("âš ï¸ æ•°æ®é˜Ÿåˆ—ä¸ºç©ºï¼Œç­‰å¾…æ•°æ®...")
                time.sleep(1)

        # è®­ç»ƒç»“æŸï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹
        save_path = "checkpoints/Terraria_final_model.pth"
        os.makedirs("checkpoints", exist_ok=True)
        torch.save(self.model.actor.state_dict(), save_path)
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {save_path}")

        print("âœ… Learner è®­ç»ƒå®Œæˆï¼Œé€šçŸ¥ Worker é€€å‡º")
        self.exit_event.set()


def train():
    mp.set_start_method("spawn", force=True)
    args = get_args()

    agent = PPO(args)
    data_queue = mp.Queue(maxsize=6000)
    param_queue = mp.Queue()
    epoch_sync_event = mp.Event()
    exit_event = mp.Event()

    workers = [Worker(i, data_queue, param_queue, epoch_sync_event, exit_event, args) for i in range(args.num_workers)]
    learner = Learner(agent, data_queue, param_queue, epoch_sync_event, exit_event, args)

    # **å¯åŠ¨ Worker å’Œ Learner**
    for w in workers:
        w.start()
    learner.start()

    # **ç­‰å¾… Learner ç»“æŸ**
    learner.join()

    # **é€šçŸ¥æ‰€æœ‰ Worker é€€å‡º**
    exit_event.set()

    # **ç­‰å¾… Worker ç»“æŸ**
    for w in workers:
        w.join()

    print("âœ… è®­ç»ƒå®Œæˆ")

if __name__ == "__main__":
    train()
