from dxcam_capture import TerrariaAimbot
from memory_read import MemoryReader  # memory_read åå­—æ— é”™è¯¯ï¼Œå‹¿ä¿®æ”¹
from keyboard_Listener import KeyActionListener
from CNNTransformer import LiteCNNTransformer
import torch
import pyautogui
import cv2
import threading
import time
import os


# å®šä¹‰æ¨¡å‹ä¿å­˜è·¯å¾„
save_dir = "./checkpoints"
os.makedirs(save_dir, exist_ok=True)
save_path = os.path.join(save_dir, "cnn_bc_train.pth")

# è®¾ç½® deviceï¼ˆGPU ä¼˜å…ˆï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# åˆå§‹åŒ–å„æ¨¡å—
aim_bot = TerrariaAimbot("E:/terraria_project/after_training_weight/10000best.pt")
reader = MemoryReader()
action_listener = KeyActionListener()

# åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ° GPU
model = LiteCNNTransformer().to(device)

if os.path.exists(save_path):
    print(f"Loading model from {save_path} ...")
    model.load_state_dict(torch.load(save_path, map_location=device))
    print("Model loaded successfully!")

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# æ ‡å¿—ä½ï¼Œè®°å½•æ˜¯å¦æ­£åœ¨å°„å‡»
is_shooting = False

# **ğŸ“Œ æ·»åŠ ä¸€ä¸ªç¼“å­˜åˆ—è¡¨æ¥å­˜å‚¨ä¸“å®¶æ•°æ®**
expert_dataset = []  # ç”¨äºå­˜å‚¨ [player_window, velocity_tensor, expert_action]


def move_and_click(target_x, target_y, boss_exist):
    """ è®©é¼ æ ‡åœ¨å­çº¿ç¨‹ä¸­ç§»åŠ¨åˆ° BOSS ä½ç½®å¹¶ç‚¹å‡» """
    global is_shooting
    pyautogui.moveTo(target_x, target_y, duration=0.002)

    if not is_shooting:  # åªæœ‰å½“æœªå°„å‡»æ—¶ï¼Œæ‰æŒ‰ä¸‹é¼ æ ‡
        pyautogui.mouseDown(button='left')
        is_shooting = True

    if not boss_exist:
        pyautogui.mouseUp(button='left')
        is_shooting = False


while True:
    last_time = time.time()

    env_data = reader.read_memory()

    # ç¡®ä¿ env_data ä¸ä¸ºç©ºå¹¶ä¸”æ•°æ®å®Œæ•´
    if env_data and len(env_data) == 6:
        player_hp, boss_hp, player_x, player_y, velocity_x, velocity_y = env_data
    else:
        print("Failed to read environment data, skipping frame...")
        continue  # è·³è¿‡å½“å‰å¾ªç¯

    # **ğŸ”¹ ç»ˆæ­¢å°„å‡»æ¡ä»¶**
    if boss_hp == -1:
        print("BOSS æ­»äº¡ï¼Œåœæ­¢é‡‡é›†æ•°æ®ï¼Œè¿›å…¥è®­ç»ƒé˜¶æ®µ...")
        break  # é€€å‡ºå¾ªç¯ï¼Œè¿›è¡Œè®­ç»ƒ

    frame = aim_bot.grab_screen()  # è·å–å®æ—¶æˆªå›¾
    boss_coord = aim_bot.boss_pos(frame)  # è¿›è¡Œç›®æ ‡æ£€æµ‹

    if frame is None or frame.size == 0:  # æ£€æŸ¥æˆªå›¾æ˜¯å¦ä¸ºç©º
        print("æˆªå›¾å¤±è´¥ï¼Œè·³è¿‡å½“å‰å¸§...")
        continue  # ç›´æ¥è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œé˜²æ­¢è®­ç»ƒå´©æºƒ

    # å¦‚æœæ£€æµ‹åˆ° BOSS ä½ç½®ï¼Œåˆ™æŒç»­å°„å‡»
    if boss_coord:
        boss_x, boss_y = boss_coord  # è§£åŒ…åæ ‡
        threading.Thread(target=move_and_click, args=(boss_x, boss_y, bool(boss_coord))).start()

    # **ğŸ“Œ å¤„ç†æ•°æ®ï¼Œå­˜å…¥ç¼“å­˜**
    # 1. å¤„ç†æˆªå›¾ï¼Œå¹¶è½¬æ¢ä¸º [1, 3, 224, 224]
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_resized = cv2.resize(frame_rgb, (224, 224))
    frame_tensor = torch.from_numpy(frame_resized).permute(2, 0, 1).float() / 255.0  # å½’ä¸€åŒ–
    player_window = frame_tensor.unsqueeze(0).to(device)  # [1, 3, 224, 224]

    # 2. å¤„ç†é€Ÿåº¦æ•°æ®ï¼Œè½¬æ¢ä¸º [1, 2]
    velocity_tensor = torch.tensor([[velocity_x, velocity_y]], dtype=torch.float32).to(device)

    # 3. è·å–ä¸“å®¶åŠ¨ä½œæ ‡ç­¾ï¼ˆone-hot æ ¼å¼ï¼‰ï¼Œå½¢çŠ¶ [1, 3]
    expert_actions = action_listener.get_action_labels().to(device)
    current_expert_action = expert_actions.clamp(min=1e-2, max=1 - 1e-2)

    # **ğŸ“Œ å­˜å‚¨æ•°æ®**
    expert_dataset.append((player_window, velocity_tensor, current_expert_action))

    print(f"Data collected: {len(expert_dataset)} frames | Spending time: {time.time() - last_time} ")

# **ç¡®ä¿é¼ æ ‡é‡Šæ”¾**
pyautogui.mouseUp(button='left')
is_shooting = False
print("é‡Šæ”¾é¼ æ ‡")

# **ğŸ“Œ è¿›å…¥è®­ç»ƒé˜¶æ®µ**
print(f"Collected {len(expert_dataset)} frames of expert data. Starting training for 100 epochs...")

batch_size = 64  # è®¾å®šæ‰¹é‡å¤§å°

for epoch in range(200):
    total_loss = 0.0
    num_batches = (len(expert_dataset) + batch_size - 1) // batch_size  # è®¡ç®—æ€»æ‰¹æ¬¡æ•°ï¼ˆå‘ä¸Šå–æ•´ï¼‰

    print(f"\nEpoch {epoch + 1}/200")  # æ‰“å° epoch å¼€å§‹

    for batch_idx, i in enumerate(range(0, len(expert_dataset), batch_size), start=1):
        batch = expert_dataset[i:i + batch_size]  # **å– batch_size ä¸ªæ ·æœ¬ï¼Œä½†æœ€åå¯èƒ½å°äº batch_size**

        if len(batch) == 0:
            continue  # é¿å…ç©º batch

        # **åˆå¹¶ batch æ•°æ®**
        player_window_batch = torch.cat([x[0] for x in batch])  # shape: [batch_size æˆ– <batch_size, 3, 224, 224]
        expert_action_batch = torch.cat([x[2] for x in batch])  # shape: [batch_size æˆ– <batch_size, action_dim]

        optimizer.zero_grad()
        loss = model.imitation_loss(expert_action_batch, player_window_batch)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        # **æ‰“å°è¿›åº¦æ¡**
        progress = batch_idx / num_batches
        bar_length = 20  # è¿›åº¦æ¡é•¿åº¦
        filled_length = int(bar_length * progress)  # å·²å¡«å……çš„é•¿åº¦
        bar = "ğŸŸ©" * filled_length + "â¬œ" * (bar_length - filled_length)  # è¿›åº¦æ¡
        percentage = progress * 100  # ç™¾åˆ†æ¯”

        print(f"\rBatch {batch_idx}/{num_batches} [{bar}] {percentage:.1f}%", end="")

    avg_loss = total_loss / num_batches
    print(f"\nEpoch {epoch + 1}/100 | Loss: {avg_loss:.6f}")

# **ğŸ“Œ è®­ç»ƒå®Œæˆåä¿å­˜æ¨¡å‹**
torch.save(model.state_dict(), save_path)
print("è®­ç»ƒç»“æŸï¼Œæ¨¡å‹å·²ä¿å­˜")
